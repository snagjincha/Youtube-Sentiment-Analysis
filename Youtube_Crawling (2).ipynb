{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7745b536-0b8a-455f-9f6e-063bb281d7ad",
   "metadata": {},
   "source": [
    "# **1. Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b942ea0-a6e5-4ff4-8298-f01f1ea3a4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/root/anaconda3/envs/ag/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline('sentiment-analysis')\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df381f3-e2c2-4197-9c07-e90c79e2296b",
   "metadata": {},
   "source": [
    "# **2. Youtube comment crawling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac922f3d-959f-40cb-9f17-f9013c78b88b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_youtube_client(api_key):\n",
    "    \"\"\"YouTube API 클라이언트 생성합니다.\"\"\"\n",
    "    return build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def get_video_id(video_address):\n",
    "    \"\"\"비디오 주소에서 비디오 ID를 추출합니다.\"\"\"\n",
    "    return video_address.split('=')[-1]\n",
    "\n",
    "def get_video_comments(youtube, video_id, max_results=100):\n",
    "    \"\"\"비디오의 댓글을 가져옵니다.\"\"\"\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            maxResults=max_results,\n",
    "            pageToken=next_page_token,\n",
    "            textFormat='plainText'\n",
    "        ).execute()\n",
    "        \n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    "        \n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "def print_comments(comments):\n",
    "    \"\"\"댓글을 출력합니다.\"\"\"\n",
    "    for i, comment in enumerate(comments, 1):\n",
    "        print(f\"{i}. {comment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc385d7-08e0-4348-9f8a-917f7933a5a0",
   "metadata": {},
   "source": [
    "## **3. Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d20b904-96a1-452d-a1b3-9e9cdc8b7b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sentiment_pipeline = pipeline('sentiment-analysis')\n",
    "\n",
    "# 감정 분석 함수\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"주어진 텍스트의 감정을 분석합니다.\"\"\"\n",
    "    result = sentiment_pipeline(text)\n",
    "    sentiment = result[0]\n",
    "    label = sentiment['label']\n",
    "    score = sentiment['score']\n",
    "    return {'label': label, 'score': score}\n",
    "\n",
    "def split_long_text(text, max_length=64):\n",
    "    \"\"\"긴 텍스트를 잘라서 반환합니다.\"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    for i in range(0, len(tokens), max_length):\n",
    "        yield ' '.join(tokens[i:i + max_length])\n",
    "\n",
    "def classify_comments(comments):\n",
    "    \"\"\"댓글을 분석하고 긍정적 또는 부정적으로 분류합니다.\"\"\"\n",
    "    good_comments = []\n",
    "    bad_comments = []\n",
    "    \n",
    "    for comment in comments:\n",
    "        for piece in split_long_text(comment):\n",
    "            sentiment = analyze_sentiment(piece)\n",
    "            \n",
    "            if sentiment['label'] == 'POSITIVE' and sentiment['score'] > 0.7:\n",
    "                good_comments.append(comment)\n",
    "            elif sentiment['label'] == 'NEGATIVE' and sentiment['score'] > 0.7:\n",
    "                bad_comments.append(comment)\n",
    "\n",
    "    return good_comments, bad_comments\n",
    "\n",
    "def print_results(comments, good_comments, bad_comments):\n",
    "    \"\"\"결과를 출력합니다.\"\"\"\n",
    "    good_count = len(good_comments)\n",
    "    bad_count = len(bad_comments)\n",
    "    \n",
    "    print(f\"Total comments: {len(comments)}\")\n",
    "    print(f\"Good comments: {good_count}\")\n",
    "    print(f\"Bad comments: {bad_count}\")\n",
    "\n",
    "    if good_count > bad_count:\n",
    "        print(\"Overall sentiment is positive.\")\n",
    "    elif bad_count > good_count:\n",
    "        print(\"Overall sentiment is negative.\")\n",
    "    else:\n",
    "        print(\"Overall sentiment is neutral.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1625ccc-2941-4c89-8ddb-b8ee9154e7c1",
   "metadata": {},
   "source": [
    "# **4. 실행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379863c-7b2c-4464-a617-91b50ce1f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(api_key, video_address):\n",
    "    \"\"\"메인 함수: 댓글을 크롤링하고 감정 분석을 수행합니다.\"\"\"\n",
    "    youtube = create_youtube_client(api_key)\n",
    "    video_id = get_video_id(video_address)\n",
    "    comments = get_video_comments(youtube, video_id)\n",
    "    \n",
    "    print_comments(comments)\n",
    "    \n",
    "    good_comments, bad_comments = classify_comments(comments)\n",
    "    print_results(comments, good_comments, bad_comments)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = 'my api'\n",
    "    video_address = 'youtube_video_address'\n",
    "    \n",
    "    main(api_key, video_address)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
